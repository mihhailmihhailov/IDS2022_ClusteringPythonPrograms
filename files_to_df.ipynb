{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import fnmatch\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell takes the path to the folder, which contains !!UNZIPPED!! folders, which contain one weeks homeworks.\n",
    "#The folders corresponding to weeks conform to the naming scheme of Zip files, but !!MANUAL UNZIPPING IS REQUIRED!!.\n",
    "\n",
    "#Unizipping via code seemed like a waste of time, compared to right-clicking and selecting \"Extract All\". :=)\n",
    "#The output is a dataframe, which feeds into the code in the next cell.\n",
    "#I am sure there is a more elegant way to do this, but this works.\n",
    "\n",
    "\n",
    "pth = ... #YOUR PATH HERE\n",
    "\n",
    "\n",
    "def studentPaths(pth):\n",
    "    pathlist1 = []\n",
    "    for p in pathlib.Path(pth).iterdir():\n",
    "        pathlist1.append(str(p))\n",
    "    return pathlist1\n",
    "ehe = studentPaths(pth)\n",
    "\n",
    "def homePaths(ehe):\n",
    "    pathlist2 = []\n",
    "    for element in ehe:\n",
    "        if element.endswith(\".ceg\"):\n",
    "            ehe.remove(element)\n",
    "            continue\n",
    "        if pathlib.Path(element).is_file():\n",
    "            continue\n",
    "        for p in pathlib.Path(element).iterdir():\n",
    "            pathlist2.append(p)\n",
    "    return pathlist2\n",
    "ehe2 = homePaths(ehe)\n",
    "def filterbyStudent(ehe2):\n",
    "    pathlist3 = []\n",
    "    pusnus = []\n",
    "    for element in ehe2:\n",
    "        if pathlib.Path(element).is_file():\n",
    "            continue\n",
    "        for p in pathlib.Path(element).iterdir():\n",
    "            pathlist3.append(p)\n",
    "    for element in pathlist3:\n",
    "        eletxt = str(element).split(\"\\\\\")\n",
    "        temp = len(eletxt)\n",
    "        esitus = eletxt[temp-1]\n",
    "        õpilane = eletxt[temp-2]\n",
    "        kodutöö = eletxt[temp-3]\n",
    "        if esitus.endswith(\".ceg\") == False:\n",
    "            pusnus.append((õpilane, kodutöö, esitus, element))\n",
    "        panda = pd.DataFrame(pusnus, columns=[\"Õpilane\", \"Kodutöö\", \"Esitus\", \"Path\"])\n",
    "    return panda\n",
    "panda = filterbyStudent(ehe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell, the dataframe is cleaned from submissions, that are not the latest.\n",
    "#The output is yet another dataframe, which is used in the next cell.\n",
    "#Using multiple data frames is not very efficient, but was helpful for debugging.\n",
    "df1 = panda.groupby(['Õpilane', 'Kodutöö', \"Path\"])['Esitus'].apply(list).reset_index()\n",
    "for index, row in df1.iterrows():\n",
    "    if row[\"Õpilane\"].startswith(\"K\"):\n",
    "        df1.drop(labels=None, axis=0, index=index, columns=None, level=None, inplace=True, errors='raise')\n",
    "        continue\n",
    "    #This chunk of code doesn't work perfectly, but it's needed for CleanDuplicates to work.\n",
    "    datetime_object = datetime.datetime(1900, 1, 1, 0, 0, 0)\n",
    "    for element in row['Esitus']:\n",
    "        datetime_objectiter = datetime.datetime.strptime(element, '%Y-%m-%d-%H-%M-%S')\n",
    "        if datetime_objectiter > datetime_object:\n",
    "            datetime_object = datetime_objectiter\n",
    "    df1.at[index, 'Esitus'] = element\n",
    "    df1.at[index, \"EsitusDT\"] = datetime_object\n",
    "    #End of aforementioned chunk of code.\n",
    "for index, row in df1.iterrows():\n",
    "    pathbits = str(row[\"Path\"]).split(\"\\\\\")\n",
    "    pathbits.pop()\n",
    "    paff = \"\\\\\".join(pathbits)\n",
    "    df1.at[index, 'Path'] = str(paff) + \"\\\\\" + str(row['Esitus'])\n",
    "    df1.at[index, 'Path'] = pathlib.Path(row[\"Path\"])\n",
    "\n",
    "def CleanDuplicates(df1):\n",
    "    df1 = df1.sort_values(by=[\"EsitusDT\"], ascending=True).drop_duplicates(subset=['Õpilane', 'Kodutöö'], keep='last')\n",
    "    return df1\n",
    "df1 = CleanDuplicates(df1)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell, the final dataframe is created. It contains all the latest submissions of all students.\n",
    "#There are 4 columns, one for the homework week, one for the student, one for the task and one for the text, in that order.\n",
    "finallist = []\n",
    "for idx, row in df1.iterrows():\n",
    "    for file in pathlib.Path(row[\"Path\"]).iterdir():\n",
    "        if fnmatch.fnmatch(file, \"*.py\"):\n",
    "            filenamebits = str(file).split(\"\\\\\")\n",
    "            temp = len(filenamebits)\n",
    "            filename = filenamebits[temp-1]\n",
    "            f = open(file, \"r\", encoding=\"utf-8\")\n",
    "            text = f.read()\n",
    "            finallist.append((row[\"Kodutöö\"], row[\"Õpilane\"],  filename, text))\n",
    "            f.close()\n",
    "df4 = pd.DataFrame(finallist, columns=[\"Kodutöö\", \"Õpilane\", \"Ülesanne\", \"Tekst\"])\n",
    "df4 = df4.sort_values(by=[\"Kodutöö\", \"Õpilane\", \"Ülesanne\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe is grouped and exported\n",
    "df4.groupby([\"Kodutöö\", \"Ülesanne\"])\n",
    "df4.to_csv(\"C:\\\\Users\\\\JuuPumal\\\\Downloads\\\\Test\\\\Masinõpe\\\\df45.csv\", encoding=\"utf-8\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1761.000000\n",
       "mean        5.466780\n",
       "std         4.029882\n",
       "min         1.000000\n",
       "25%         2.000000\n",
       "50%         5.000000\n",
       "75%         9.000000\n",
       "max        12.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Due to issues with duplicates, this dataframe displays the number of submissions per student per task.\n",
    "#The greatest possible number of submissions from 1 student, for all the weeks, is 13 per task.\n",
    "\n",
    "#In reality, the maximum number is 12, for task 1, since for week 2, the counting starts from kodu2.\n",
    "#Task 2 goes up to 11, since week 1 only has 1 task and in week 8, kodu2 is called film instead.\n",
    "#Task 3 and 4 are lower, since they are not present for every week.\n",
    "\n",
    "#Considering the above, .describe is only used to check for the maximum value. Mean and median are not very informative, due to the presence of outliers (film appears only once etc.).\n",
    "df_sanity = df4.groupby(\"Õpilane\").value_counts([\"Ülesanne\"])\n",
    "df_sanity.to_csv(\"C:\\\\Users\\\\JuuPumal\\\\Downloads\\\\Test\\\\Masinõpe\\\\df_sanity.csv\", encoding=\"utf-8\", index=True, sep=\";\")\n",
    "df_sanity.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "312b26a9cbaa7a4a6bcc14a6c8a15dee997f5cec64160ff37a1842933dd8d098"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
